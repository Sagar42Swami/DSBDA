{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d3a0b8-2b10-4810-a2d3-e76ce9530cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f27f19-e47a-4168-b1ab-e61a082be27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "Information about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "\n",
      "Summary statistics of the dataset:\n",
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "\n",
      "Distribution of the target variable:\n",
      "species\n",
      "setosa        50\n",
      "versicolor    50\n",
      "virginica     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('iris.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Get some basic information about the dataset\n",
    "print(\"\\nInformation about the dataset:\")\n",
    "print(data.info())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics of the dataset:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Check the distribution of the target variable\n",
    "print(\"\\nDistribution of the target variable:\")\n",
    "print(data['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d53b8e-79ea-473f-a2c5-189aa4519123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded target variable (first 10 values): [0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Mapping of encoded values to original species: {np.int64(0): 'setosa', np.int64(1): 'versicolor', np.int64(2): 'virginica'}\n",
      "\n",
      "Shape of X_train: (105, 4)\n",
      "Shape of X_test: (45, 4)\n",
      "Shape of y_train: (105,)\n",
      "Shape of y_test: (45,)\n"
     ]
    }
   ],
   "source": [
    "# Select features (independent variables) and target (dependent variable)\n",
    "X = data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = data['species']\n",
    "\n",
    "# Encode the target variable (species) into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "print(\"\\nEncoded target variable (first 10 values):\", y_encoded[:10])\n",
    "print(\"\\nMapping of encoded values to original species:\", dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_)))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"\\nShape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2769ca4-2342-4a1d-add2-6f87f06bd544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions on the test set (encoded):\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 2 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "\n",
      "Predictions on the test set (original species):\n",
      "['versicolor' 'setosa' 'virginica' 'versicolor' 'versicolor' 'setosa'\n",
      " 'versicolor' 'virginica' 'versicolor' 'versicolor' 'virginica' 'setosa'\n",
      " 'setosa' 'setosa' 'setosa' 'virginica' 'virginica' 'versicolor'\n",
      " 'versicolor' 'virginica' 'setosa' 'virginica' 'setosa' 'virginica'\n",
      " 'virginica' 'virginica' 'virginica' 'virginica' 'setosa' 'setosa'\n",
      " 'setosa' 'setosa' 'versicolor' 'setosa' 'setosa' 'virginica' 'versicolor'\n",
      " 'setosa' 'setosa' 'setosa' 'virginica' 'versicolor' 'versicolor' 'setosa'\n",
      " 'setosa']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the Gaussian Na√Øve Bayes model\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nPredictions on the test set (encoded):\")\n",
    "print(y_pred)\n",
    "\n",
    "# Convert the encoded predictions back to original species names (optional, for better understanding)\n",
    "y_pred_original = label_encoder.inverse_transform(y_pred)\n",
    "print(\"\\nPredictions on the test set (original species):\")\n",
    "print(y_pred_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4516611-d73f-4a83-ad91-82bf4096fa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Accuracy: 0.9777777777777777\n",
      "Error Rate: 0.022222222222222254\n",
      "Precision: 0.9793650793650793\n",
      "Recall: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# For multi-class, TP, FP, TN, FN are not as straightforward as in binary classification.\n",
    "# The confusion matrix itself provides a detailed view of the classification performance per class.\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "\n",
    "# Compute Error Rate\n",
    "error_rate = 1 - accuracy\n",
    "print(\"Error Rate:\", error_rate)\n",
    "\n",
    "# Compute Precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted') # Using 'weighted' for multi-class\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Compute Recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted') # Using 'weighted' for multi-class\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c759d-16b9-4ff8-9c93-2328a1227fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
